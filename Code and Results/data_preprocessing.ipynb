{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e025467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec1e3c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING DATASET\n",
      "================================================================================\n",
      "Loaded 43571 records\n",
      "Columns: ['scrape_id', 'product_name', 'category', 'subcategory', 'brand', 'gender_target', 'price_raw', 'size_raw', 'retailer', 'url', 'description', 'ingredients']\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\"*80)\n",
    "df = pd.read_csv('raw_scraped_data_3261_inr.csv')\n",
    "print(f\"Loaded {len(df)} records\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "881b9922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 1: EDA & AUDIT\n",
      "================================================================================\n",
      "\n",
      "1.1 Basic Info:\n",
      "   Total records: 43571\n",
      "   Columns: 12\n",
      "   Memory usage: 38.44 MB\n",
      "\n",
      "1.2 Missing Values:\n",
      "               Missing Count  Percentage\n",
      "ingredients            13344       30.63\n",
      "gender_target           5178       11.88\n",
      "description             2442        5.60\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 1: EDA & AUDIT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1.1 Basic Info:\")\n",
    "print(f\"   Total records: {len(df)}\")\n",
    "print(f\"   Columns: {len(df.columns)}\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n1.2 Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_report = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Missing Count', ascending=False)\n",
    "print(missing_report[missing_report['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf86591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.3 Data Types:\n",
      "scrape_id        object\n",
      "product_name     object\n",
      "category         object\n",
      "subcategory      object\n",
      "brand            object\n",
      "gender_target    object\n",
      "price_raw        object\n",
      "size_raw         object\n",
      "retailer         object\n",
      "url              object\n",
      "description      object\n",
      "ingredients      object\n",
      "dtype: object\n",
      "\n",
      "1.4 Sample Records:\n",
      "  scrape_id                         product_name category  subcategory      brand gender_target    price_raw size_raw         retailer                                          url                                                             description                                        ingredients\n",
      "0    S02968                   Reebok Supplements     Toys  Supplements     reebok           NaN  5764.35 INR       1g  RelianceDigital  https://www.reliancedigital.com/dp/WLSLRYA5                               Moisturizing formula with essential oils.  Tea Tree Oil, Water, Coconut Oil, Sodium Chloride\n",
      "1    S00135             Gillette Razor - Men - 5  Shaving        Razor   Gillette           Men     Rs298.58        5            Nykaa            https://www.nykaa.com/dp/19ZGX30U        Advanced formula Razor by Gillette for long-lasting performance.                                                NaN\n",
      "2    S01738  Sensodyne Toothpaste - Women - 50ml  Hygiene   Toothpaste  Sensodyne         Women     ₹ 340.98       50       HealthKart       https://www.healthkart.com/dp/JPISGR6X  Advanced formula Toothpaste by Sensodyne for long-lasting performance.                   Retinol, Keratin, Salicylic Acid\n",
      "\n",
      "1.5 Gender Distribution:\n",
      "gender_target\n",
      "Men              15276\n",
      "Women            15210\n",
      "NaN               5178\n",
      "Unisex            2316\n",
      "M                 1494\n",
      "F                 1440\n",
      "female            1362\n",
      "male              1290\n",
      "gender_target        5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1.6 Category Distribution (top 10):\n",
      "category\n",
      "Personal Care        15612\n",
      "Clothing              7920\n",
      "Hygiene               5184\n",
      "Footwear              3156\n",
      "Health                2916\n",
      "Toys & Stationery     1818\n",
      "Shaving               1506\n",
      "Accessories           1500\n",
      "Baby                  1008\n",
      "Home & Living          876\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1.7 Brand Distribution (top 10):\n",
      "brand\n",
      "Nivea       1554\n",
      "Dettol      1368\n",
      "Adidas      1320\n",
      "Nike        1314\n",
      "Olay        1290\n",
      "Gillette    1272\n",
      "Uniqlo      1260\n",
      "Garnier     1248\n",
      "Dove        1248\n",
      "Colgate     1176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1.8 Retailer Distribution:\n",
      "retailer\n",
      "Croma              4602\n",
      "Nykaa              4530\n",
      "HealthKart         4440\n",
      "Myntra             4416\n",
      "PharmEasy          4368\n",
      "RelianceDigital    4338\n",
      "Amazon.in          4314\n",
      "BigBasket          4266\n",
      "Ajio               4242\n",
      "Flipkart           4050\n",
      "retailer              5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1.9 Price Patterns:\n",
      "price_raw\n",
      "353rs       24\n",
      "Rs. 460     24\n",
      "₹ 509       24\n",
      "₹ 396       18\n",
      "Rs.517/-    18\n",
      "630 INR     18\n",
      "232rs       18\n",
      "₹ 144       18\n",
      "Rs.497/-    18\n",
      "Rs.839/-    18\n",
      "Name: count, dtype: int64\n",
      "\n",
      "1.10 Size Patterns:\n",
      "size_raw\n",
      "100         2268\n",
      "50          1668\n",
      "150         1476\n",
      "200         1188\n",
      "1L          1086\n",
      "100L        1032\n",
      "100g        1020\n",
      "1count       942\n",
      "100pcs       936\n",
      "100count     924\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n1.3 Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n1.4 Sample Records:\")\n",
    "print(df.head(3).to_string())\n",
    "\n",
    "print(\"\\n1.5 Gender Distribution:\")\n",
    "print(df['gender_target'].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n1.6 Category Distribution (top 10):\")\n",
    "print(df['category'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n1.7 Brand Distribution (top 10):\")\n",
    "print(df['brand'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n1.8 Retailer Distribution:\")\n",
    "print(df['retailer'].value_counts())\n",
    "\n",
    "print(\"\\n1.9 Price Patterns:\")\n",
    "print(df['price_raw'].value_counts().head(10))\n",
    "\n",
    "print(\"\\n1.10 Size Patterns:\")\n",
    "print(df['size_raw'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81374d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 2: CLEANING & NORMALIZATION\n",
      "================================================================================\n",
      "\n",
      "2.1 Normalizing brand names...\n",
      "   Unique brands: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 2: CLEANING & NORMALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 2.1 Clean Brand Names\n",
    "print(\"\\n2.1 Normalizing brand names...\")\n",
    "def clean_brand(brand):\n",
    "    if pd.isna(brand):\n",
    "        return 'Unknown'\n",
    "    brand = str(brand).strip()\n",
    "    # Remove special characters and extra spaces\n",
    "    brand = re.sub(r'[^\\w\\s&\\'-]', '', brand)\n",
    "    brand = re.sub(r'\\s+', ' ', brand)\n",
    "    # Remove common suffixes\n",
    "    brand = re.sub(r'\\s+(Pvt|Ltd|Limited|India|Inc|Corp|Co|Private)(\\s+|$)', '', brand, flags=re.IGNORECASE)\n",
    "    # Capitalize properly\n",
    "    brand = brand.title()\n",
    "    # Handle specific brand normalizations\n",
    "    brand_map = {\n",
    "        \"L'Oreal\": \"L'Oréal\",\n",
    "        \"Loreal\": \"L'Oréal\",\n",
    "        \"L'Orã©Al\": \"L'Oréal\",\n",
    "        \"Park Avenue\": \"Park Avenue\",\n",
    "        \"Forest Essential\": \"Forest Essentials\",\n",
    "        \"Himalaya Wellness\": \"Himalaya\",\n",
    "    }\n",
    "    for old, new in brand_map.items():\n",
    "        if old.lower() in brand.lower():\n",
    "            brand = new\n",
    "            break\n",
    "    return brand\n",
    "\n",
    "df_clean['brand'] = df_clean['brand'].apply(clean_brand)\n",
    "print(f\"   Unique brands: {df_clean['brand'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "581a27b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.2 Normalizing categories...\n",
      "   Records after filtering valid categories: 36294\n",
      "\n",
      "2.3 Normalizing prices...\n",
      "   Valid prices: 36294/36294\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Normalize Category and Subcategory\n",
    "print(\"\\n2.2 Normalizing categories...\")\n",
    "def clean_category(cat):\n",
    "    if pd.isna(cat):\n",
    "        return 'Unknown'\n",
    "    cat = str(cat).strip().title()\n",
    "    # Remove extra spaces\n",
    "    cat = re.sub(r'\\s+', ' ', cat)\n",
    "    return cat\n",
    "\n",
    "df_clean['category'] = df_clean['category'].apply(clean_category)\n",
    "df_clean['subcategory'] = df_clean['subcategory'].apply(clean_category)\n",
    "\n",
    "# Filter out nonsensical categories\n",
    "valid_categories = ['Personal Care', 'Clothing', 'Footwear', 'Shaving', 'Hygiene', 'Health']\n",
    "df_clean = df_clean[df_clean['category'].isin(valid_categories)]\n",
    "print(f\"   Records after filtering valid categories: {len(df_clean)}\")\n",
    "\n",
    "# 2.3 Clean and Normalize Prices\n",
    "print(\"\\n2.3 Normalizing prices...\")\n",
    "def extract_price(price_str):\n",
    "    if pd.isna(price_str):\n",
    "        return np.nan\n",
    "    # Remove currency symbols and extract number\n",
    "    price_str = str(price_str)\n",
    "    # Extract all numbers (including decimals)\n",
    "    matches = re.findall(r'\\d+\\.?\\d*', price_str)\n",
    "    if matches:\n",
    "        return float(matches[0])\n",
    "    return np.nan\n",
    "\n",
    "df_clean['price'] = df_clean['price_raw'].apply(extract_price)\n",
    "print(f\"   Valid prices: {df_clean['price'].notna().sum()}/{len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1adf1ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.4 Normalizing sizes...\n",
      "   Valid sizes: 35532/36294\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Clean and Normalize Sizes\n",
    "print(\"\\n2.4 Normalizing sizes...\")\n",
    "def extract_size_and_unit(size_str):\n",
    "    if pd.isna(size_str):\n",
    "        return np.nan, 'Unknown'\n",
    "    size_str = str(size_str).strip()\n",
    "    \n",
    "    # Extract number and unit\n",
    "    match = re.search(r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)', size_str)\n",
    "    if match:\n",
    "        size_value = float(match.group(1))\n",
    "        unit = match.group(2).lower()\n",
    "        \n",
    "        # Normalize units\n",
    "        unit_map = {\n",
    "            'ml': 'ml', 'milliliter': 'ml', 'millilitre': 'ml',\n",
    "            'l': 'ml', 'liter': 'ml', 'litre': 'ml',  # Will convert L to ml\n",
    "            'g': 'g', 'gram': 'g', 'gm': 'g',\n",
    "            'kg': 'g', 'kilogram': 'g',  # Will convert kg to g\n",
    "            'oz': 'oz', 'ounce': 'oz',\n",
    "            'count': 'count', 'pcs': 'count', 'pieces': 'count',\n",
    "            's': 'size_s', 'm': 'size_m', 'l': 'size_l', 'xl': 'size_xl',\n",
    "            'xxl': 'size_xxl'\n",
    "        }\n",
    "        \n",
    "        normalized_unit = unit_map.get(unit, unit)\n",
    "        \n",
    "        # Convert units to base units\n",
    "        if unit == 'l':\n",
    "            size_value = size_value * 1000  # L to ml\n",
    "            normalized_unit = 'ml'\n",
    "        elif unit == 'kg':\n",
    "            size_value = size_value * 1000  # kg to g\n",
    "            normalized_unit = 'g'\n",
    "        \n",
    "        return size_value, normalized_unit\n",
    "    \n",
    "    # If no unit found, check if it's a clothing size\n",
    "    size_str_upper = size_str.upper()\n",
    "    if size_str_upper in ['XS', 'S', 'M', 'L', 'XL', 'XXL', 'XXXL']:\n",
    "        return 1, f'size_{size_str_upper.lower()}'\n",
    "    \n",
    "    # Check if it's just a number (for counts)\n",
    "    if size_str.isdigit():\n",
    "        return float(size_str), 'count'\n",
    "    \n",
    "    return np.nan, 'Unknown'\n",
    "\n",
    "df_clean[['size', 'size_unit']] = df_clean['size_raw'].apply(\n",
    "    lambda x: pd.Series(extract_size_and_unit(x))\n",
    ")\n",
    "print(f\"   Valid sizes: {df_clean['size'].notna().sum()}/{len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7595af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.5 Normalizing gender...\n",
      "gender_target\n",
      "Men        16074\n",
      "Women      16050\n",
      "Unknown     2988\n",
      "Unisex      1182\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2.5 Normalize Gender\n",
    "print(\"\\n2.5 Normalizing gender...\")\n",
    "def clean_gender(gender):\n",
    "    if pd.isna(gender):\n",
    "        return 'Unknown'\n",
    "    gender = str(gender).strip().title()\n",
    "    if gender in ['Men', 'Male', 'M']:\n",
    "        return 'Men'\n",
    "    elif gender in ['Women', 'Female', 'F', 'Woman']:\n",
    "        return 'Women'\n",
    "    elif gender in ['Unisex', 'Both', 'All']:\n",
    "        return 'Unisex'\n",
    "    return 'Unknown'\n",
    "\n",
    "df_clean['gender_target'] = df_clean['gender_target'].apply(clean_gender)\n",
    "print(df_clean['gender_target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d64dbb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.6 Cleaning product names...\n",
      "\n",
      "2.7 Calculating normalized price per unit...\n",
      "   Calculated price per unit for 35370 records\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Clean Product Names\n",
    "print(\"\\n2.6 Cleaning product names...\")\n",
    "def clean_product_name(name):\n",
    "    if pd.isna(name):\n",
    "        return 'Unknown Product'\n",
    "    name = str(name).strip()\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    return name\n",
    "\n",
    "df_clean['product_name'] = df_clean['product_name'].apply(clean_product_name)\n",
    "\n",
    "# 2.7 Calculate normalized price per unit\n",
    "print(\"\\n2.7 Calculating normalized price per unit...\")\n",
    "def calculate_price_per_unit(row):\n",
    "    if pd.isna(row['price']) or pd.isna(row['size']) or row['size'] == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # For volume/weight units, calculate price per unit\n",
    "    if row['size_unit'] in ['ml', 'g', 'oz']:\n",
    "        return round(row['price'] / row['size'], 2)\n",
    "    # For clothing sizes and counts, price is already per item\n",
    "    elif row['size_unit'].startswith('size_') or row['size_unit'] == 'count':\n",
    "        return row['price']\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "df_clean['normalized_price_per_unit'] = df_clean.apply(calculate_price_per_unit, axis=1)\n",
    "print(f\"   Calculated price per unit for {df_clean['normalized_price_per_unit'].notna().sum()} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48cf8672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.8 Data after cleaning:\n",
      "   Total records: 36294\n",
      "   Valid prices: 36294\n",
      "   Valid sizes: 35532\n",
      "   Valid price per unit: 35370\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2.8 Data after cleaning:\")\n",
    "print(f\"   Total records: {len(df_clean)}\")\n",
    "print(f\"   Valid prices: {df_clean['price'].notna().sum()}\")\n",
    "print(f\"   Valid sizes: {df_clean['size'].notna().sum()}\")\n",
    "print(f\"   Valid price per unit: {df_clean['normalized_price_per_unit'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cacf239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 3: DEDUPLICATION\n",
      "================================================================================\n",
      "\n",
      "3.1 Records before deduplication: 36294\n",
      "3.2 Records after removing exact duplicates: 6047\n",
      "3.3 Records after removing near-duplicates: 3374\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 3: DEDUPLICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n3.1 Records before deduplication: {len(df_clean)}\")\n",
    "\n",
    "# Remove exact duplicates\n",
    "df_clean = df_clean.drop_duplicates(\n",
    "    subset=['product_name', 'brand', 'category', 'gender_target', 'price', 'size'],\n",
    "    keep='first'\n",
    ")\n",
    "print(f\"3.2 Records after removing exact duplicates: {len(df_clean)}\")\n",
    "\n",
    "# Remove near-duplicates (same product, brand, gender, but slightly different price/size)\n",
    "df_clean = df_clean.drop_duplicates(\n",
    "    subset=['product_name', 'brand', 'category', 'subcategory', 'gender_target'],\n",
    "    keep='first'\n",
    ")\n",
    "print(f\"3.3 Records after removing near-duplicates: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9519ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 4: GENDER TAGGING & FILTERING\n",
      "================================================================================\n",
      "\n",
      "4.1 Gender distribution before filtering:\n",
      "gender_target\n",
      "Men        1353\n",
      "Women      1334\n",
      "Unknown     493\n",
      "Unisex      194\n",
      "Name: count, dtype: int64\n",
      "\n",
      "4.2 Records after filtering for gendered products: 2687\n",
      "\n",
      "4.3 Gender distribution after filtering:\n",
      "gender_target\n",
      "Men      1353\n",
      "Women    1334\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 4: GENDER TAGGING & FILTERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n4.1 Gender distribution before filtering:\")\n",
    "print(df_clean['gender_target'].value_counts())\n",
    "\n",
    "# Keep only records with clear gender tags (Men or Women)\n",
    "df_gendered = df_clean[df_clean['gender_target'].isin(['Men', 'Women'])].copy()\n",
    "print(f\"\\n4.2 Records after filtering for gendered products: {len(df_gendered)}\")\n",
    "\n",
    "print(\"\\n4.3 Gender distribution after filtering:\")\n",
    "print(df_gendered['gender_target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39a64f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STAGE 5: PRODUCT MATCHING (PAIRING)\n",
      "================================================================================\n",
      "\n",
      "5.1 Preparing for matching...\n",
      "\n",
      "5.2 Finding potential pairs...\n",
      "   Men's products: 1353\n",
      "   Women's products: 1334\n",
      "\n",
      "5.3 Total pairs found: 534\n",
      "\n",
      "5.4 Pair statistics:\n",
      "   Average price difference: ₹71.98\n",
      "   Average price difference %: 41.35%\n",
      "   Products where women pay more: 378\n",
      "   Products where men pay more: 155\n",
      "   Products with same price: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STAGE 5: PRODUCT MATCHING (PAIRING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n5.1 Preparing for matching...\")\n",
    "\n",
    "# Remove gender-specific terms from product names for matching\n",
    "def create_matching_key(row):\n",
    "    name = row['product_name'].lower()\n",
    "    # Remove gender indicators\n",
    "    name = re.sub(r'\\s*-?\\s*(men|women|male|female|man|woman)\\s*-?\\s*', ' ', name, flags=re.IGNORECASE)\n",
    "    # Remove size from name\n",
    "    name = re.sub(r'\\s*-?\\s*\\d+\\s*(ml|g|l|oz|count|pcs|s|m|l|xl|xxl)\\s*-?\\s*', ' ', name, flags=re.IGNORECASE)\n",
    "    # Remove extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    # Create key: brand_category_subcategory_cleanedname_size_unit\n",
    "    key = f\"{row['brand']}_{row['category']}_{row['subcategory']}_{name}_{row['size']}_{row['size_unit']}\"\n",
    "    return key.lower()\n",
    "\n",
    "df_gendered['matching_key'] = df_gendered.apply(create_matching_key, axis=1)\n",
    "\n",
    "# Find potential pairs\n",
    "print(\"\\n5.2 Finding potential pairs...\")\n",
    "men_products = df_gendered[df_gendered['gender_target'] == 'Men'].copy()\n",
    "women_products = df_gendered[df_gendered['gender_target'] == 'Women'].copy()\n",
    "\n",
    "print(f\"   Men's products: {len(men_products)}\")\n",
    "print(f\"   Women's products: {len(women_products)}\")\n",
    "\n",
    "# Match products by matching key\n",
    "pairs = []\n",
    "pair_id = 1\n",
    "\n",
    "for _, men_row in men_products.iterrows():\n",
    "    matching_women = women_products[women_products['matching_key'] == men_row['matching_key']]\n",
    "    \n",
    "    if len(matching_women) > 0:\n",
    "        # Take the first match (or could do more sophisticated matching)\n",
    "        women_row = matching_women.iloc[0]\n",
    "        \n",
    "        pairs.append({\n",
    "            'pair_id': f'PAIR{pair_id:05d}',\n",
    "            'men_scrape_id': men_row['scrape_id'],\n",
    "            'women_scrape_id': women_row['scrape_id'],\n",
    "            'brand': men_row['brand'],\n",
    "            'category': men_row['category'],\n",
    "            'subcategory': men_row['subcategory'],\n",
    "            'size': men_row['size'],\n",
    "            'size_unit': men_row['size_unit'],\n",
    "            'men_price': men_row['price'],\n",
    "            'women_price': women_row['price'],\n",
    "            'price_diff': women_row['price'] - men_row['price'],\n",
    "            'price_diff_pct': ((women_row['price'] - men_row['price']) / men_row['price'] * 100) if men_row['price'] > 0 else 0\n",
    "        })\n",
    "        pair_id += 1\n",
    "\n",
    "print(f\"\\n5.3 Total pairs found: {len(pairs)}\")\n",
    "\n",
    "# Create pairs dataframe\n",
    "df_pairs = pd.DataFrame(pairs)\n",
    "\n",
    "if len(df_pairs) > 0:\n",
    "    print(\"\\n5.4 Pair statistics:\")\n",
    "    print(f\"   Average price difference: ₹{df_pairs['price_diff'].mean():.2f}\")\n",
    "    print(f\"   Average price difference %: {df_pairs['price_diff_pct'].mean():.2f}%\")\n",
    "    print(f\"   Products where women pay more: {(df_pairs['price_diff'] > 0).sum()}\")\n",
    "    print(f\"   Products where men pay more: {(df_pairs['price_diff'] < 0).sum()}\")\n",
    "    print(f\"   Products with same price: {(df_pairs['price_diff'] == 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62b1a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING FINAL DATASET\n",
      "================================================================================\n",
      "\n",
      "✓ Final dataset created with 1068 records (534 pairs)\n",
      "\n",
      "Column structure:\n",
      "['product_id', 'pair_id', 'product_name', 'category', 'subcategory', 'brand', 'gender_target', 'price', 'size', 'normalized_price_per_unit', 'retailer', 'description', 'ingredients']\n",
      "\n",
      "Sample records:\n",
      "  product_id    pair_id                         product_name       category  subcategory     brand gender_target   price   size  normalized_price_per_unit   retailer                                                       description                                                                ingredients\n",
      "0   P00001_M  PAIR00001             Gillette Razor - Men - 5        Shaving        Razor  Gillette           Men  298.58    5.0                     298.58      Nykaa  Advanced formula Razor by Gillette for long-lasting performance.                                                                           \n",
      "1   P00001_F  PAIR00001           Gillette Razor - Women - 5        Shaving        Razor  Gillette         Women  297.42    5.0                     297.42      Nykaa  Advanced formula Razor by Gillette for long-lasting performance.                                                                           \n",
      "2   P00002_M  PAIR00002    L'Oréal Moisturizer - Men - 150ml  Personal Care  Moisturizer   L'Oréal           Men  292.12  150.0                     292.12       Ajio  L'Oréal presents a gentle Moisturizer with enriched ingredients.                 Glycerin, Shea Butter, Sodium Chloride, Water, Niacinamide\n",
      "3   P00002_F  PAIR00002  L'Oréal Moisturizer - Women - 150ml  Personal Care  Moisturizer   L'Oréal         Women  847.40  150.0                     847.40  Amazon.in      Lightweight Moisturizer from L'Oréal — dermatologist tested.  Tea Tree Oil, Cocamidopropyl Betaine, Coconut Oil, Sodium Laureth Sulfate\n",
      "\n",
      "✓ Final dataset saved to: pink_tax_cleaned_paired_dataset.csv\n",
      "✓ Pairs summary saved to: product_pairs_summary.csv\n",
      "\n",
      "================================================================================\n",
      "PIPELINE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "DATA PROCESSING PIPELINE - SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "INPUT DATA:\n",
      "  • Raw records loaded: 43571\n",
      "  • Columns: 12\n",
      "\n",
      "STAGE 1 - EDA & AUDIT:\n",
      "  • Missing values identified: 3 columns with missing data\n",
      "  • Data quality issues: Price format variations, size format inconsistencies\n",
      "  \n",
      "STAGE 2 - CLEANING & NORMALIZATION:\n",
      "  • Records after category filtering: 3374\n",
      "  • Brands normalized: 33 unique brands\n",
      "  • Prices normalized: 3374 valid prices\n",
      "  • Sizes normalized: 3310 valid sizes\n",
      "  • Price per unit calculated: 3286 records\n",
      "\n",
      "STAGE 3 - DEDUPLICATION:\n",
      "  • Records before: 3374\n",
      "  • Records after: 3374\n",
      "  • Duplicates removed: Exact and near-duplicates\n",
      "\n",
      "STAGE 4 - GENDER FILTERING:\n",
      "  • Records with clear gender tags: 2687\n",
      "  • Men's products: 1353\n",
      "  • Women's products: 1334\n",
      "\n",
      "STAGE 5 - PRODUCT PAIRING:\n",
      "  • Total pairs found: 534\n",
      "  • Final dataset size: 1068 records (534 pairs × 2)\n",
      "  \n",
      "PINK TAX INSIGHTS (from pairs):\n",
      "  • Products where women pay MORE: 378\n",
      "  • Products where men pay MORE: 155\n",
      "  • Products with SAME price: 1\n",
      "  • Average price difference: ₹71.98\n",
      "  • Average % difference: 41.35%\n",
      "\n",
      "OUTPUT FILES:\n",
      "  ✓ pink_tax_cleaned_paired_dataset.csv - Final dataset with all required columns\n",
      "  ✓ product_pairs_summary.csv - Pair-level analysis\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "✓ Summary report saved to: pipeline_summary_report.txt\n",
      "\n",
      "================================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING FINAL DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Prepare final dataset with all pairs\n",
    "final_records = []\n",
    "product_counter = 1\n",
    "\n",
    "for _, pair in df_pairs.iterrows():\n",
    "    # Get full records for men and women\n",
    "    men_rec = men_products[men_products['scrape_id'] == pair['men_scrape_id']].iloc[0]\n",
    "    women_rec = women_products[women_products['scrape_id'] == pair['women_scrape_id']].iloc[0]\n",
    "    \n",
    "    # Men's record\n",
    "    final_records.append({\n",
    "        'product_id': f'P{product_counter:05d}_M',\n",
    "        'pair_id': pair['pair_id'],\n",
    "        'product_name': men_rec['product_name'],\n",
    "        'category': men_rec['category'],\n",
    "        'subcategory': men_rec['subcategory'],\n",
    "        'brand': men_rec['brand'],\n",
    "        'gender_target': 'Men',\n",
    "        'price': men_rec['price'],\n",
    "        'size': men_rec['size'],\n",
    "        'normalized_price_per_unit': men_rec['normalized_price_per_unit'],\n",
    "        'retailer': men_rec['retailer'],\n",
    "        'description': men_rec['description'] if pd.notna(men_rec['description']) else '',\n",
    "        'ingredients': men_rec['ingredients'] if pd.notna(men_rec['ingredients']) else ''\n",
    "    })\n",
    "    \n",
    "    # Women's record\n",
    "    final_records.append({\n",
    "        'product_id': f'P{product_counter:05d}_F',\n",
    "        'pair_id': pair['pair_id'],\n",
    "        'product_name': women_rec['product_name'],\n",
    "        'category': women_rec['category'],\n",
    "        'subcategory': women_rec['subcategory'],\n",
    "        'brand': women_rec['brand'],\n",
    "        'gender_target': 'Women',\n",
    "        'price': women_rec['price'],\n",
    "        'size': women_rec['size'],\n",
    "        'normalized_price_per_unit': women_rec['normalized_price_per_unit'],\n",
    "        'retailer': women_rec['retailer'],\n",
    "        'description': women_rec['description'] if pd.notna(women_rec['description']) else '',\n",
    "        'ingredients': women_rec['ingredients'] if pd.notna(women_rec['ingredients']) else ''\n",
    "    })\n",
    "    \n",
    "    product_counter += 1\n",
    "\n",
    "df_final = pd.DataFrame(final_records)\n",
    "\n",
    "print(f\"\\n✓ Final dataset created with {len(df_final)} records ({len(df_final)//2} pairs)\")\n",
    "print(f\"\\nColumn structure:\")\n",
    "print(df_final.columns.tolist())\n",
    "\n",
    "print(\"\\nSample records:\")\n",
    "print(df_final.head(4).to_string())\n",
    "\n",
    "# Save the final dataset\n",
    "output_path = 'pink_tax_cleaned_paired_dataset.csv'\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"\\n✓ Final dataset saved to: {output_path}\")\n",
    "\n",
    "# Save the pairs summary\n",
    "pairs_summary_path = 'product_pairs_summary.csv'\n",
    "df_pairs.to_csv(pairs_summary_path, index=False)\n",
    "print(f\"✓ Pairs summary saved to: {pairs_summary_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# GENERATE SUMMARY REPORT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "avg_price_diff = df_pairs['price_diff'].mean() if len(df_pairs) > 0 else 0\n",
    "avg_pct_diff = df_pairs['price_diff_pct'].mean() if len(df_pairs) > 0 else 0\n",
    "women_pay_more = (df_pairs['price_diff'] > 0).sum() if len(df_pairs) > 0 else 0\n",
    "men_pay_more = (df_pairs['price_diff'] < 0).sum() if len(df_pairs) > 0 else 0\n",
    "same_price = (df_pairs['price_diff'] == 0).sum() if len(df_pairs) > 0 else 0\n",
    "\n",
    "summary = f\"\"\"\n",
    "DATA PROCESSING PIPELINE - SUMMARY REPORT\n",
    "{'='*80}\n",
    "\n",
    "INPUT DATA:\n",
    "  • Raw records loaded: {len(df)}\n",
    "  • Columns: {len(df.columns)}\n",
    "\n",
    "STAGE 1 - EDA & AUDIT:\n",
    "  • Missing values identified: {missing[missing > 0].count()} columns with missing data\n",
    "  • Data quality issues: Price format variations, size format inconsistencies\n",
    "  \n",
    "STAGE 2 - CLEANING & NORMALIZATION:\n",
    "  • Records after category filtering: {len(df_clean)}\n",
    "  • Brands normalized: {df_clean['brand'].nunique()} unique brands\n",
    "  • Prices normalized: {df_clean['price'].notna().sum()} valid prices\n",
    "  • Sizes normalized: {df_clean['size'].notna().sum()} valid sizes\n",
    "  • Price per unit calculated: {df_clean['normalized_price_per_unit'].notna().sum()} records\n",
    "\n",
    "STAGE 3 - DEDUPLICATION:\n",
    "  • Records before: {len(df_clean)}\n",
    "  • Records after: {len(df_clean)}\n",
    "  • Duplicates removed: Exact and near-duplicates\n",
    "\n",
    "STAGE 4 - GENDER FILTERING:\n",
    "  • Records with clear gender tags: {len(df_gendered)}\n",
    "  • Men's products: {len(men_products)}\n",
    "  • Women's products: {len(women_products)}\n",
    "\n",
    "STAGE 5 - PRODUCT PAIRING:\n",
    "  • Total pairs found: {len(df_pairs)}\n",
    "  • Final dataset size: {len(df_final)} records ({len(df_final)//2} pairs × 2)\n",
    "  \n",
    "PINK TAX INSIGHTS (from pairs):\n",
    "  • Products where women pay MORE: {women_pay_more}\n",
    "  • Products where men pay MORE: {men_pay_more}\n",
    "  • Products with SAME price: {same_price}\n",
    "  • Average price difference: ₹{avg_price_diff:.2f}\n",
    "  • Average % difference: {avg_pct_diff:.2f}%\n",
    "\n",
    "OUTPUT FILES:\n",
    "  ✓ pink_tax_cleaned_paired_dataset.csv - Final dataset with all required columns\n",
    "  ✓ product_pairs_summary.csv - Pair-level analysis\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary report\n",
    "with open('pipeline_summary_report.txt', 'w') as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"\\n✓ Summary report saved to: pipeline_summary_report.txt\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387d12b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
